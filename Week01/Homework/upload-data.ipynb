{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-01-17 10:46:20--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/ea580e9e-555c-4bd0-ae73-43051d8e7c0b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250116%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250116T234621Z&X-Amz-Expires=300&X-Amz-Signature=ff0106bea8f160b6823abc6e6f835ec3fcd35f4a31135923e8e5fdaff45ae8b1&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-01-17 10:46:21--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/ea580e9e-555c-4bd0-ae73-43051d8e7c0b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250116%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250116T234621Z&X-Amz-Expires=300&X-Amz-Signature=ff0106bea8f160b6823abc6e6f835ec3fcd35f4a31135923e8e5fdaff45ae8b1&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8262584 (7.9M) [application/octet-stream]\n",
      "Saving to: ‘green_tripdata_2019-10.csv.gz’\n",
      "\n",
      "green_tripdata_2019 100%[===================>]   7.88M  7.07MB/s    in 1.1s    \n",
      "\n",
      "2025-01-17 10:46:23 (7.07 MB/s) - ‘green_tripdata_2019-10.csv.gz’ saved [8262584/8262584]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-01-17 10:48:45--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250116%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250116T234846Z&X-Amz-Expires=300&X-Amz-Signature=e2542999eea3bfc97dcb4b4e47264026bf3ec52d6b164f396bfee8540843c3de&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-01-17 10:48:46--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250116%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250116T234846Z&X-Amz-Expires=300&X-Amz-Signature=e2542999eea3bfc97dcb4b4e47264026bf3ec52d6b164f396bfee8540843c3de&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi_zone_lookup.csv’\n",
      "\n",
      "taxi_zone_lookup.cs 100%[===================>]  12.03K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2025-01-17 10:48:47 (21.4 MB/s) - ‘taxi_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zones = pd.read_csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xt/7gvkdnw143dgfgsp73bsn11w0000gn/T/ipykernel_5512/652255458.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  green_tripdata = pd.read_csv('green_tripdata_2019-10.csv.gz', compression='gzip')\n"
     ]
    }
   ],
   "source": [
    "green_tripdata = pd.read_csv('green_tripdata_2019-10.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 476386 entries, 0 to 476385\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   VendorID               387007 non-null  float64       \n",
      " 1   lpep_pickup_datetime   476386 non-null  datetime64[ns]\n",
      " 2   lpep_dropoff_datetime  476386 non-null  datetime64[ns]\n",
      " 3   store_and_fwd_flag     387007 non-null  object        \n",
      " 4   RatecodeID             387007 non-null  float64       \n",
      " 5   PULocationID           476386 non-null  int64         \n",
      " 6   DOLocationID           476386 non-null  int64         \n",
      " 7   passenger_count        387007 non-null  float64       \n",
      " 8   trip_distance          476386 non-null  float64       \n",
      " 9   fare_amount            476386 non-null  float64       \n",
      " 10  extra                  476386 non-null  float64       \n",
      " 11  mta_tax                476386 non-null  float64       \n",
      " 12  tip_amount             476386 non-null  float64       \n",
      " 13  tolls_amount           476386 non-null  float64       \n",
      " 14  ehail_fee              0 non-null       float64       \n",
      " 15  improvement_surcharge  476386 non-null  float64       \n",
      " 16  total_amount           476386 non-null  float64       \n",
      " 17  payment_type           387007 non-null  float64       \n",
      " 18  trip_type              387005 non-null  float64       \n",
      " 19  congestion_surcharge   387007 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(15), int64(2), object(1)\n",
      "memory usage: 72.7+ MB\n"
     ]
    }
   ],
   "source": [
    "green_tripdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_tripdata.lpep_pickup_datetime = pd.to_datetime(green_tripdata.lpep_pickup_datetime)\n",
    "green_tripdata.lpep_dropoff_datetime = pd.to_datetime(green_tripdata.lpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_zones.to_sql(name='taxi_zones', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_tripdata.head(0).to_sql(name='green_tripdata', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476386, 20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_tripdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_tripdata_iter = pd.read_csv('green_tripdata_2019-10.csv.gz', iterator=True, chunksize=100000, compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk, took 3.328 second\n",
      "inserted another chunk, took 2.750 second\n",
      "inserted another chunk, took 2.637 second\n",
      "inserted another chunk, took 3.438 second\n",
      "inserted another chunk, took 4.588 second\n",
      "inserted another chunk, took 2.796 second\n",
      "inserted another chunk, took 2.615 second\n",
      "inserted another chunk, took 2.335 second\n",
      "inserted another chunk, took 3.231 second\n",
      "inserted another chunk, took 3.082 second\n",
      "inserted another chunk, took 2.734 second\n",
      "inserted another chunk, took 3.242 second\n",
      "inserted another chunk, took 2.820 second\n",
      "inserted another chunk, took 2.758 second\n",
      "inserted another chunk, took 3.357 second\n",
      "inserted another chunk, took 3.159 second\n",
      "inserted another chunk, took 3.045 second\n",
      "inserted another chunk, took 2.816 second\n",
      "inserted another chunk, took 2.835 second\n",
      "inserted another chunk, took 2.736 second\n",
      "inserted another chunk, took 2.669 second\n",
      "inserted another chunk, took 2.967 second\n",
      "inserted another chunk, took 3.788 second\n",
      "inserted another chunk, took 3.258 second\n",
      "inserted another chunk, took 4.160 second\n",
      "inserted another chunk, took 3.998 second\n",
      "inserted another chunk, took 3.194 second\n",
      "inserted another chunk, took 2.876 second\n",
      "inserted another chunk, took 3.832 second\n",
      "inserted another chunk, took 2.765 second\n",
      "inserted another chunk, took 3.417 second\n",
      "inserted another chunk, took 3.144 second\n",
      "inserted another chunk, took 2.702 second\n",
      "inserted another chunk, took 3.158 second\n",
      "inserted another chunk, took 3.081 second\n",
      "inserted another chunk, took 2.770 second\n",
      "inserted another chunk, took 2.718 second\n",
      "inserted another chunk, took 2.673 second\n",
      "inserted another chunk, took 2.646 second\n",
      "inserted another chunk, took 2.205 second\n",
      "inserted another chunk, took 2.461 second\n",
      "inserted another chunk, took 2.231 second\n",
      "inserted another chunk, took 2.469 second\n",
      "inserted another chunk, took 2.442 second\n",
      "inserted another chunk, took 2.350 second\n",
      "inserted another chunk, took 2.544 second\n",
      "inserted another chunk, took 2.248 second\n",
      "inserted another chunk, took 1.437 second\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/zhaohengchuan/Desktop/workSpace/Data-Engineering-ZoomCamp-2025/Week01/Homework/upload-data.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zhaohengchuan/Desktop/workSpace/Data-Engineering-ZoomCamp-2025/Week01/Homework/upload-data.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m: \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zhaohengchuan/Desktop/workSpace/Data-Engineering-ZoomCamp-2025/Week01/Homework/upload-data.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     t_start \u001b[39m=\u001b[39m time()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/zhaohengchuan/Desktop/workSpace/Data-Engineering-ZoomCamp-2025/Week01/Homework/upload-data.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     df \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(green_tripdata_iter)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zhaohengchuan/Desktop/workSpace/Data-Engineering-ZoomCamp-2025/Week01/Homework/upload-data.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     df\u001b[39m.\u001b[39mlpep_pickup_datetime \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df\u001b[39m.\u001b[39mlpep_pickup_datetime)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zhaohengchuan/Desktop/workSpace/Data-Engineering-ZoomCamp-2025/Week01/Homework/upload-data.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     df\u001b[39m.\u001b[39mlpep_dropoff_datetime \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df\u001b[39m.\u001b[39mlpep_dropoff_datetime)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1843\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   1842\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1843\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_chunk()\n\u001b[1;32m   1844\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m   1845\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1985\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1983\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1984\u001b[0m     size \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnrows \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_currow)\n\u001b[0;32m-> 1985\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nrows\u001b[39m=\u001b[39;49msize)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m         nrows\n\u001b[1;32m   1925\u001b[0m     )\n\u001b[1;32m   1926\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:863\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True: \n",
    "    t_start = time()\n",
    "\n",
    "    df = next(green_tripdata_iter)\n",
    "\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    \n",
    "    df.to_sql(name='green_tripdata', con=engine, if_exists='append')\n",
    "\n",
    "    t_end = time()\n",
    "\n",
    "    print('inserted another chunk, took %.3f second' % (t_end - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
